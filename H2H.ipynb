{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWMU9fiTRm3IZoP1lLqSXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonkwokth/TableTennisPrediction/blob/dev/H2H.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bMA550fvMHMq",
        "outputId": "176dc00a-4ba9-4710-8ef3-1a1f56791e93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TableTennisPrediction' already exists and is not an empty directory.\n",
            "/content/TableTennisPrediction\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ansonkwokth/TableTennisPrediction.git\n",
        "%cd TableTennisPrediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from utils import data_loader as dl\n",
        "\n",
        "import numpy as np\n",
        "# from model.Elo import Elo\n",
        "from model.ModifiedElo import ModifiedElo\n",
        "# from model.ensemble import BaggingRatingSystem\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import copy\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "fgfuNcLqMPPO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "zL9XnSNXVA-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GAME = 'TTStar'\n",
        "# GAME = 'TTCup'\n",
        "# GAME = 'SetkaCup'\n",
        "GAME = 'SetkaCupWomen'\n",
        "# GAME = 'LigaPro'\n"
      ],
      "metadata": {
        "id": "vEfGED5M7Pa2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match GAME:\n",
        "    case 'TTStar':\n",
        "        years = [2020, 2021, 2022, 2023, 2024]\n",
        "    case 'TTCup':\n",
        "        years = [2020, 2021, 2022, 2023, 2024]\n",
        "    case 'SetkaCup':\n",
        "        years = [2020, 2021, 2022, 2023, 2024]\n",
        "    case 'SetkaCupWomen':\n",
        "        years = [2020, 2021, 2022, 2023, 2024]\n",
        "    case 'LigaPro':\n",
        "        years = [2022, 2023, 2024]\n",
        "    case _:\n",
        "        raise ValueError(\"Invalid game selected.\")\n",
        "\n",
        "\n",
        "text_data_game = dl.load_game_data(GAME, years, '../')\n",
        "text_data = {\n",
        "    year: text_data_game[year] for year in years\n",
        "}\n",
        "df = dl.create_game_dfs(GAME, years, text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYKKHO267cRc",
        "outputId": "1eef6838-a0f8-4688-9abc-9eba82ee933f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ..//SetkaCupWomen2020.txt\n",
            "Loading ..//SetkaCupWomen2021.txt\n",
            "Loading ..//SetkaCupWomen2022.txt\n",
            "Loading ..//SetkaCupWomen2023.txt\n",
            "Loading ..//SetkaCupWomen2024.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate ID indices for each pair of rows in the DataFrame\n",
        "idx_lt = [i for i in range(len(df) // 2) for _ in range(2)]\n",
        "df['ID'] = idx_lt  # Assign to the 'ID' column\n",
        "\n",
        "# Reset the DataFrame index to ensure it's sequential\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Get unique players and store them in player_lt\n",
        "player_lt = df['Player'].unique()\n",
        "\n"
      ],
      "metadata": {
        "id": "L8oBW_wk7uvM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year_val = years[-2]\n",
        "year_test = years[-1]\n",
        "\n",
        "\n",
        "df = df.sort_values(['ID', 'Player'])\n",
        "df_train = df.loc[pd.DatetimeIndex(df['Date']).year < year_val]\n",
        "df_val = df.loc[pd.DatetimeIndex(df['Date']).year == year_val]\n",
        "df_train_val = df.loc[pd.DatetimeIndex(df['Date']).year <= year_val]\n",
        "df_test = df.loc[pd.DatetimeIndex(df['Date']).year == year_test]\n"
      ],
      "metadata": {
        "id": "tC-31F8o7dPX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_to_array(df: pd.DataFrame) -> np.ndarray:\n",
        "\n",
        "    # info_col = ['ID', 'Round', 'Datetime', 'Game', 'Date', 'Time']\n",
        "    info_col = ['Round', 'Datetime', 'Game', 'Date', 'Time']\n",
        "    col = [item for item in df.columns if item not in info_col]\n",
        "\n",
        "    df[[c for c in col if \"Set\" in c]] = df[[c for c in col if \"Set\" in c]].astype(float)\n",
        "    X = df[col].values.reshape(-1, 2, len(col))\n",
        "    return X"
      ],
      "metadata": {
        "id": "fdILJrB5Mcyj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = format_to_array(df_train)\n",
        "X_val = format_to_array(df_val)\n",
        "X_train_val = format_to_array(df_train_val)\n",
        "X_test = format_to_array(df_test)"
      ],
      "metadata": {
        "id": "-gLXcFEvMePw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all = format_to_array(df)"
      ],
      "metadata": {
        "id": "Pzkb-m1iMe6N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modelMElo = ModifiedElo()\n",
        "\n",
        "# # traing model with only training set\n",
        "# for _ in range(5):\n",
        "#     modelMElo.fit(X_train)\n"
      ],
      "metadata": {
        "id": "3VNdJLC6Mflz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# H2H histroy"
      ],
      "metadata": {
        "id": "XIun4YcCgT_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SymmetricTable:\n",
        "    def __init__(self):\n",
        "        self.data = {}\n",
        "\n",
        "    def add(self, key1, key2, value):\n",
        "        \"\"\"Append value to the list corresponding to the symmetric key.\"\"\"\n",
        "        key = tuple(sorted([key1, key2]))\n",
        "        if key not in self.data:\n",
        "            self.data[key] = []\n",
        "        self.data[key].append(value)\n",
        "\n",
        "    def get(self, key1, key2):\n",
        "        \"\"\"Retrieve the list of values for the given symmetric key, defaulting to an empty list.\"\"\"\n",
        "        return self.data.get(tuple(sorted([key1, key2])), [])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3Pe-IdHegT3P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Id and the corresponding past h2h history before this match\n",
        "h2h_rate_mean = {}\n",
        "h2h_rate_median = {}\n",
        "table = SymmetricTable()\n",
        "SETCOL = [i for i in df_train.columns if 'Set' in i]\n",
        "\n",
        "\n",
        "for id in tqdm(df.ID.unique()):\n",
        "    df_i = df[df.ID == id]\n",
        "\n",
        "    player1, player2 = df_i.Player.values\n",
        "    # all the historical sets\n",
        "    histo_rate = table.get(player1, player2)\n",
        "    # the mean of the win rate\n",
        "    histo_rate_mean = np.mean(histo_rate)\n",
        "    histo_rate_median = np.median(histo_rate)\n",
        "    # add to the dict\n",
        "    h2h_rate_mean[id] = histo_rate_mean\n",
        "    h2h_rate_median[id] = histo_rate_median\n",
        "\n",
        "    df_p_i = df_i.sort_values(\"Player\")\n",
        "    # the scores of the sets\n",
        "    scores = df_p_i[SETCOL].values\n",
        "    winrate_i = (scores[0] / (scores[0] + scores[1]))\n",
        "\n",
        "    # add the current set results to the history\n",
        "    for wi in winrate_i:\n",
        "        if np.isnan(wi): continue\n",
        "        table.add(player1, player2, wi)\n"
      ],
      "metadata": {
        "id": "dgM35OwjrqEd",
        "outputId": "c7afc0c4-db5e-4417-d4e9-be986e6c654b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 34579/34579 [00:43<00:00, 789.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "histo_rate"
      ],
      "metadata": {
        "id": "5oPErmGTxlHu",
        "outputId": "a315f264-b36b-456d-9210-5bde1813a260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Id and the corresponding past h2h history before this match\n",
        "h2h_rate_IQR = {}\n",
        "table = SymmetricTable()\n",
        "SETCOL = [i for i in df_train.columns if 'Set' in i]\n",
        "\n",
        "\n",
        "for id in tqdm(df.ID.unique()):\n",
        "    df_i = df[df.ID == id]\n",
        "\n",
        "    player1, player2 = df_i.Player.values\n",
        "    # all the historical sets\n",
        "    histo_rate = table.get(player1, player2)\n",
        "    # the mean of the win rate\n",
        "    # print(histo_rate)\n",
        "    if len(histo_rate) > 0:\n",
        "\n",
        "        Q1 = np.percentile(histo_rate, 25)\n",
        "        Q3 = np.percentile(histo_rate, 75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        # Define outlier range\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        histo_rate = np.array(histo_rate)\n",
        "\n",
        "        # Filter out outliers\n",
        "        filtered_histo_rate = histo_rate[(histo_rate >= lower_bound) & (histo_rate <= upper_bound)]\n",
        "\n",
        "        histo_rate_mean = np.mean(filtered_histo_rate)\n",
        "    else:\n",
        "\n",
        "        histo_rate_mean = np.mean(histo_rate)\n",
        "\n",
        "    # add to the dict\n",
        "    h2h_rate_IQR[id] = histo_rate_mean\n",
        "\n",
        "    df_p_i = df_i.sort_values(\"Player\")\n",
        "    # the scores of the sets\n",
        "    scores = df_p_i[SETCOL].values\n",
        "    winrate_i = (scores[0] / (scores[0] + scores[1]))\n",
        "\n",
        "    # add the current set results to the history\n",
        "    for wi in winrate_i:\n",
        "        if np.isnan(wi): continue\n",
        "        table.add(player1, player2, wi)\n"
      ],
      "metadata": {
        "id": "DJ0YpjbfqjvK",
        "outputId": "a30485e8-7b2f-47f1-83e0-deaeb208b995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 34579/34579 [00:50<00:00, 682.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvSsmQEqgT0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4rRUfIrkg2xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Look at the relation"
      ],
      "metadata": {
        "id": "GG7PKGPLqSjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_point(model, dataset, h2h):\n",
        "    print(f\"Evaluate model: {repr(model)}\")\n",
        "    _model = copy.deepcopy(model)\n",
        "    _model.verbose = False\n",
        "\n",
        "    history = []\n",
        "    predictions = []\n",
        "    h2hs = []\n",
        "    for idx, matchi in tqdm(enumerate(dataset), desc=\"Evaluating matches\"):\n",
        "        id = matchi[0, 0]\n",
        "        matchi = matchi.T\n",
        "        h2hi = h2h[id]\n",
        "        player1, player2 = matchi[1]\n",
        "\n",
        "        found_p1, found_p2, p = _model.predict_point(player1, player2)\n",
        "        if not (found_p1 and found_p2): continue\n",
        "        if p == 0.5: continue\n",
        "\n",
        "        for seti in matchi[2:]:\n",
        "            if np.isnan(seti[0]) or (seti[0] + seti[1]) == 0: break\n",
        "            winrate = seti[0] / (seti[0] + seti[1])\n",
        "            history.append(winrate)\n",
        "            predictions.append(p)\n",
        "            h2hs.append(h2hi)\n",
        "\n",
        "\n",
        "    return np.array(history), np.array(predictions), np.array(h2hs)\n",
        "\n"
      ],
      "metadata": {
        "id": "1gC_QS4PiMfo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist, pred, h2h = evaluate_point(modelMElo, X_train, h2h_rate)\n",
        "# hist, pred, h2h = evaluate_point(modelMElo, X_val, h2h_rate)\n",
        "# hist, pred, h2h = evaluate_point(modelMElo, X_test, h2h_rate)\n",
        "# hist, pred = evaluate_point(modelMElo, X_val)"
      ],
      "metadata": {
        "id": "K8JueV2biMjf",
        "outputId": "f0026352-a45c-499c-f724-974b5e88a9ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'modelMElo' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-992e623807a1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelMElo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2h_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# hist, pred, h2h = evaluate_point(modelMElo, X_val, h2h_rate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# hist, pred, h2h = evaluate_point(modelMElo, X_test, h2h_rate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# hist, pred = evaluate_point(modelMElo, X_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'modelMElo' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit_hist = np.log(hist / (1-hist))\n",
        "logit_pred = np.log(pred / (1-pred))\n",
        "residul = logit_hist - logit_pred\n",
        "residul = np.nan_to_num(residul, nan=np.nan, posinf=np.nan, neginf=np.nan)\n",
        "plt.hist(residul);\n"
      ],
      "metadata": {
        "id": "DkFkdvnriMnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(logit_hist, logit_pred, alpha=0.05)\n",
        "\n"
      ],
      "metadata": {
        "id": "OpMqOLP1DRbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit_h2h = np.log(h2h / (1-h2h))\n",
        "logit_h2h = np.nan_to_num(logit_h2h, nan=np.nan, posinf=np.nan, neginf=np.nan)\n",
        "plt.hist(logit_h2h);\n"
      ],
      "metadata": {
        "id": "XRYwF2kkiM7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\hat{y}=\\frac{1}{1+\\exp{(-x)}}$\n",
        "\n",
        "$\\hat{y}^{(0)}=\\frac{1}{1+\\exp{(-\\Delta S)}}$, $\\Delta S\\equiv S_1 - S_2$\n",
        "\n",
        "$\\hat{x}^{(1)}=\\Delta S + \\epsilon_{\\rm H}\\Delta H$\n",
        "\n",
        "Fir the residual:\n",
        "\n",
        "$R\\equiv x - \\Delta S = \\epsilon_{\\rm H}\\Delta H$.\n",
        "\n",
        "After fitting the $\\hat{\\epsilon}_{\\rm H}$, then do $\\hat{x}^{(1)} = \\Delta S + \\hat{\\epsilon}_{\\rm H}\\Delta H$"
      ],
      "metadata": {
        "id": "hbAuEXDv_ctO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S54iINXyx7Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "comb = np.array([logit_h2h, residul])\n",
        "\n",
        "comb = comb[:, ~(abs(comb)<=1e-10).any(axis=0)]\n",
        "comb = comb[:, ~(abs(comb)>=1e10).any(axis=0)]\n",
        "comb = comb[:, ~np.any(np.isnan(comb), axis=0)]"
      ],
      "metadata": {
        "id": "XTkKowYgx6hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(comb[0], comb[1], alpha=0.05)\n",
        "plt.xlabel(\"$\\Delta H$\")\n",
        "plt.ylabel(\"$R$\")\n"
      ],
      "metadata": {
        "id": "5qE_Ucb83niU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "x = comb[0]    # Delta H\n",
        "y = comb[1].reshape(-1, 1)    # Residual\n",
        "ols = sm.OLS(y, x)\n",
        "ols_result = ols.fit()\n",
        "print(ols_result.summary())\n",
        "eps = ols_result.params[0]\n",
        "eps"
      ],
      "metadata": {
        "id": "Yd35Z_JkmF3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression().fit(x.reshape(-1, 1), y)\n",
        "reg.coef_\n"
      ],
      "metadata": {
        "id": "WztrjNbtKtTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.scatter(reg.predict(x.reshape(-1, 1)), y, alpha=0.05)\n",
        "# plt.scatter(x, y, alpha=0.05)"
      ],
      "metadata": {
        "id": "NUXBCR4VLGpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.cm as cm\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "\n",
        "\n",
        "def myplot(x, y, s, bins=1000):\n",
        "    heatmap, xedges, yedges = np.histogram2d(x, y, bins=bins)\n",
        "    heatmap = gaussian_filter(heatmap, sigma=s)\n",
        "\n",
        "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
        "    return heatmap.T, extent\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "\n",
        "# Generate some test data\n",
        "x, y = comb[0], comb[1]\n",
        "\n",
        "sigmas = [0, 16, 32, 64]\n",
        "\n",
        "for ax, s in zip(axs.flatten(), sigmas):\n",
        "    if s == 0:\n",
        "        ax.plot(x, y, 'k.', markersize=5)\n",
        "        ax.set_title(\"Scatter plot\")\n",
        "    else:\n",
        "        img, extent = myplot(x, y, s)\n",
        "        ax.imshow(img, origin='lower', cmap=cm.jet)\n",
        "        ax.set_title(\"Smoothing with  $\\sigma$ = %d\" % s)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "91PJbu4chHJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap, xedges, yedges = np.histogram2d(x, y, bins=50)\n",
        "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
        "\n",
        "plt.clf()\n",
        "plt.imshow(heatmap.T, extent=extent, origin='lower')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TkoKPhWdmF63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eps = 0.23\n",
        "y_rot = logit_pred + eps*logit_h2h\n",
        "comb_rot = np.array([y_rot, logit_hist])\n",
        "\n",
        "y_rot = eps*logit_h2h\n",
        "comb_rot = np.array([y_rot, residul])\n",
        "\n",
        "comb_rot = comb_rot[:, ~(abs(comb_rot)<=1e-10).any(axis=0)]\n",
        "comb_rot = comb_rot[:, ~(abs(comb_rot)>=1e10).any(axis=0)]\n",
        "comb_rot = comb_rot[:, ~np.any(np.isnan(comb_rot), axis=0)]\n",
        "\n",
        "\n",
        "heatmap, xedges, yedges = np.histogram2d(comb_rot[0], comb_rot[1], bins=50)\n",
        "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
        "\n",
        "plt.clf()\n",
        "plt.imshow(heatmap.T, extent=extent, origin='lower')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0GkCbSo4mF-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_rot = reg.predict(np.nan_to_num(logit_h2h.reshape(-1, 1), 0)).reshape(1, -1)[0] + logit_pred\n",
        "pred_1 = 1 / (1 + np.exp(-y_rot))\n"
      ],
      "metadata": {
        "id": "YXhEKYGNhHD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pred_1, pred, alpha=0.05)"
      ],
      "metadata": {
        "id": "dETcWK2BMHm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GFANnD_YO8FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit_hist = np.log(hist / (1-hist))\n",
        "\n",
        "residul = logit_hist - y_rot\n",
        "residul = np.nan_to_num(residul, nan=np.nan, posinf=np.nan, neginf=np.nan)\n",
        "plt.hist(residul, histtype='step', range=[-3.5, 3.5], bins=10);\n",
        "\n",
        "logit_hist = np.log(hist / (1-hist))\n",
        "logit_pred = np.log(pred / (1-pred))\n",
        "residul = logit_hist - logit_pred\n",
        "residul = np.nan_to_num(residul, nan=np.nan, posinf=np.nan, neginf=np.nan)\n",
        "plt.hist(residul, histtype='step', range=[-3.5, 3.5], bins=10);\n"
      ],
      "metadata": {
        "id": "8Z9qMBfCO7Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(np.round(hist) == np.round(pred)) / len(hist)"
      ],
      "metadata": {
        "id": "_1m7AnaiLT9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(np.round(hist) == np.round(y_rot.reshape(1, -1)[0])) / len(hist)"
      ],
      "metadata": {
        "id": "oWEAssb8LUAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9Tk5zURLUHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-5XSM4KLUKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Model with H2H"
      ],
      "metadata": {
        "id": "7Ik8UoXE_uo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from math import comb\n",
        "\n",
        "\n",
        "\n",
        "class RatingSystem2:\n",
        "\n",
        "    def __init__(self, learning_rate=32, binary=False, verbose=False):\n",
        "\n",
        "        if not isinstance(learning_rate, (float, int)):\n",
        "            raise TypeError(f\"Expected 'learning_rate' to be an float/int, but got {type(learning_rate).__name__}\")\n",
        "        if learning_rate <= 0:\n",
        "            raise ValueError(f\"Expected 'learning_rate' to be positive, but got {learning_rate}\")\n",
        "\n",
        "        if not isinstance(verbose, bool):\n",
        "            raise TypeError(f\"Expected 'verbose' to be an bool, but got {type(verbose).__name__}\")\n",
        "\n",
        "        self.params = {}\n",
        "        self.learning_rate = learning_rate\n",
        "        self.binary = binary\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self._found_p1 = None\n",
        "        self._found_p2 = None\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _add_sigma(sigma1, sigma2):\n",
        "        return np.sqrt(sigma1**2 + sigma2**2)\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _logit(p):\n",
        "        return np.log(p / (1 - p))\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def predict_set_config_from_p(p):\n",
        "        q = 1 - p\n",
        "        dt = {}\n",
        "        # Calculate probabilities for the first 10+ points won by player 1\n",
        "        for i in range(10):\n",
        "            prob = comb(10 + i, 10) * p**11 * q**i\n",
        "            dt[10 + i + 1] = prob  # Store probability for player 1 winning 11, 12, ... points\n",
        "        # Calculate probability for the special case of winning exactly 22 points\n",
        "        dt[22] = (1 / (1 - 2 * q * p)) * comb(20, 10) * p**12 * q**10\n",
        "        return dt\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def predict_game_config_from_p(p, n_win_sets=3):\n",
        "        # Ensure n_win_sets is odd\n",
        "        if n_win_sets % 2 == 0:\n",
        "            raise ValueError(\"'n_win_sets' must be an odd number.\")\n",
        "        q = 1 - p\n",
        "        dt = {}\n",
        "        # Calculate probabilities for winning n_win_sets, n_win_sets+1, ...\n",
        "        for i in range(n_win_sets):\n",
        "            prob = comb(n_win_sets - 1 + i, n_win_sets - 1) * p**n_win_sets * q**i\n",
        "            dt[n_win_sets + i] = prob  # Store probability for winning sets\n",
        "        return dt\n",
        "\n",
        "\n",
        "\n",
        "    def get_player_param(self, player):\n",
        "        return self._get_player_param(player)\n",
        "\n",
        "\n",
        "\n",
        "    def _predict_point(self, player1, player2, feature=None):\n",
        "        \"\"\"\n",
        "        Predict the probability of Player 1 winning a point against Player 2.\n",
        "\n",
        "        :param player1: Name of Player 1.\n",
        "        :param player2: Name of Player 2.\n",
        "        :return: Probability of Player 1 winning a point.\n",
        "        \"\"\"\n",
        "        self._prediction_verbose(player1, player1)\n",
        "        self._found_p1, param1 = self._get_player_param(player1)\n",
        "        self._found_p2, param2 = self._get_player_param(player2)\n",
        "        prob = self._expected_prob(param1, param2)\n",
        "        if feature is not None:\n",
        "            prob = self._correction_prob(prob, feature)\n",
        "        return prob\n",
        "\n",
        "\n",
        "\n",
        "    def predict_point(self, player1, player2, feature=None):\n",
        "        p = self._predict_point(player1, player2, feature)\n",
        "        return self._found_p1, self._found_p2, p\n",
        "\n",
        "\n",
        "    def predict_set_config(self, player1, player2, feature=None):\n",
        "        \"\"\"\n",
        "        Predict the probability of Player 1 winning a set against Player 2,\n",
        "        with total points being 'n', in the set.\n",
        "        For each possible 'n', calculate the corresponding prob.\n",
        "\n",
        "        :param player1: Name of Player 1.\n",
        "        :param player2: Name of Player 2.\n",
        "        :return: dict of probabilities of Player 1 winning the set with total 'n' points.\n",
        "        \"\"\"\n",
        "        ps = self.predict_set_config_from_p(self._predict_point(player1, player2, feature))\n",
        "        return self._found_p1, self._found_p2, ps\n",
        "\n",
        "\n",
        "    def predict_set(self, player1, player2, feature=None):\n",
        "        \"\"\"\n",
        "        Predict the probability of Player 1 winning a set against Player 2,\n",
        "\n",
        "        :param player1: Name of Player 1.\n",
        "        :param player2: Name of Player 2.\n",
        "        :return: Probability of Player 1 winning the set\n",
        "        \"\"\"\n",
        "        _, _, ps = self.predict_set_config(player1, player2, feature)\n",
        "        return self._found_p1, self._found_p2, sum(ps.values())\n",
        "\n",
        "\n",
        "    def predict_game_config(self, player1, player2, feature=None, n_win_sets=3):\n",
        "        \"\"\"\n",
        "        Predict the probability of Player 1 winning the game against Player 2,\n",
        "        with total number of sets being 'n', in the game.\n",
        "        For each possible 'n', calculate the corresponding prob.\n",
        "\n",
        "        :param player1: Name of Player 1.\n",
        "        :param player2: Name of Player 2.\n",
        "        :param n_win_sets: Number of winning sets to win the game\n",
        "        :return: dict of probabilities of Player 1 winning the game with total 'n' sets.\n",
        "        \"\"\"\n",
        "        _, _, p_set = self.predict_set(player1, player2, feature)\n",
        "        p = self.predict_game_config_from_p(p_set, n_win_sets)\n",
        "        return self._found_p1, self._found_p2, p\n",
        "\n",
        "\n",
        "    def predict_game(self, player1, player2, feature=None):\n",
        "        \"\"\"\n",
        "        Predict the probability of Player 1 winning the game against Player 2,\n",
        "\n",
        "        :param player1: Name of Player 1.\n",
        "        :param player2: Name of Player 2.\n",
        "        :return: Probability of Player 1 winning the game\n",
        "        \"\"\"\n",
        "        _, _, ps = self.predict_game_config(player1, player2, feature)\n",
        "        return self._found_p1, self._found_p2, sum(ps.values())\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, dataset, features=None):\n",
        "        \"\"\"\n",
        "        Fit the model to a dataset of matches.\n",
        "\n",
        "        :param dataset: an array with shape (m, 2, s)\n",
        "                        with m = number of matches\n",
        "                             2 = 1v1\n",
        "                             s = max number of sets in the dataset\n",
        "                        Note that it must be sorted with time\n",
        "                        for example:\n",
        "                        array([[['Reitspies D.', 11.0, 11.0, ..., nan, nan, nan],\n",
        "                                ['Gavlas A.', 9.0, 9.0, ..., nan, nan, nan]],\n",
        "\n",
        "                            [['Kleprlik J.', 3.0, 4.0, ..., nan, nan, nan],\n",
        "                                ['Prokopcov D.', 11.0, 11.0, ..., nan, nan, nan]],\n",
        "\n",
        "                            [['Horejsi M.', 11.0, 11.0, ..., 7.0, 9.0, nan],\n",
        "                                ['Tregler T.', 4.0, 8.0, ..., 11.0, 11.0, nan]],\n",
        "        \"\"\"\n",
        "        # loop over matches\n",
        "        for matchi in tqdm(dataset, desc=\"Training model\"):\n",
        "            matchi = matchi.T\n",
        "            # the first row are the players\n",
        "            player1, player2 = matchi[1]\n",
        "            id = matchi[0, 0]\n",
        "            feature = features[id] if features is not None else None\n",
        "\n",
        "            # loop over sets in the match\n",
        "            for seti in matchi[2:]:\n",
        "                points1, points2 = seti\n",
        "                # skip nan entries\n",
        "                if np.isnan(points1) or np.isnan(points2): continue\n",
        "                # skip total points = 0\n",
        "                points_sum = points1 + points2\n",
        "                if points_sum == 0: continue\n",
        "\n",
        "                result1 = points1 / points_sum\n",
        "                if self.binary: result1 = result1 = 1 if result1 > 0.5 else 0\n",
        "\n",
        "                # Add players to the system if they are not already in\n",
        "                self._add_player(player1)\n",
        "                self._add_player(player2)\n",
        "\n",
        "                # Update ratings based on the match result\n",
        "                if feature is not None:\n",
        "\n",
        "                    self._update_params(player1, player2, result1, feature)\n",
        "                else:\n",
        "                    self._update_params(player1, player2, result1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QS29QoCVB27T"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class ModifiedEloH2H(RatingSystem2):\n",
        "    def __init__(self, learning_rate=0.1, base_param=(0, 1), eps_h2h=0.1, update_sigma=True, binary=False, verbose=False):\n",
        "        \"\"\"\n",
        "        Initialize the rating system.\n",
        "\n",
        "        :param learning_rate: Learning rate.\n",
        "        :param params: Parameters for the players.\n",
        "        :param update_sigma: Update also sigma during the gradient descent.\n",
        "        \"\"\"\n",
        "        super().__init__(learning_rate=learning_rate, binary=binary, verbose=verbose)\n",
        "\n",
        "        if not isinstance(base_param, tuple):\n",
        "            raise TypeError(f\"Expected 'base_param' to be a tuple, but got {type(base_param).__name__}\")\n",
        "        if len(base_param) != 2:\n",
        "            raise ValueError(f\"Expected 'value' to be a 2-entry tuple, but got {len(base_param)} entries\")\n",
        "        if not all(isinstance(entry, (int, float)) for entry in base_param):\n",
        "            raise TypeError(\"Both entries in 'base_param' must be float/int\")\n",
        "        if base_param[1] <= 0:\n",
        "            raise ValueError(f\"The second entry in 'base_param' must be greater than 0, but got {base_param[1]}\")\n",
        "\n",
        "        if not isinstance(update_sigma, bool):\n",
        "            raise TypeError(f\"Expected 'update_sigma' to be an bool, but got {type(update_sigma).__name__}\")\n",
        "\n",
        "        self.params = {}\n",
        "        self.eps_h2h = eps_h2h\n",
        "        self.base_param = base_param\n",
        "        self.update_sigma = update_sigma\n",
        "\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"ModifiedElo(learning_rate={self.learning_rate}, base_param={self.base_param}, update_sigma={self.update_sigma}, verbose={self.verbose})\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _get_player_param(self, player):\n",
        "        \"\"\"\n",
        "        Retrieve the current rating of a player. If the player does not exist, use the default.\n",
        "\n",
        "        :param player: The player's name.\n",
        "        :return: Current rating of the player.\n",
        "        \"\"\"\n",
        "        return (player in self.params), self.params.get(player, self.base_param)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _expected_prob(self, param1, param2):\n",
        "        \"\"\"\n",
        "        Calculate the expected prob. of winning a point.\n",
        "\n",
        "        :param param1: Parameters of Player 1.\n",
        "        :param param2: Parameters of Player 2.\n",
        "        :return: Expected prob for Player 1.\n",
        "        \"\"\"\n",
        "        # Calculate the combined sigma and the difference in mu values\n",
        "        z = (param1[0] - param2[0]) / self._add_sigma(param1[1], param2[1])\n",
        "        # Calculate the predicted probability using the logistic function\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "\n",
        "    def _correction_prob(self, prob, h2h):\n",
        "        logit_prob = self._logit(prob)\n",
        "        logit_h2h = self._logit(h2h)\n",
        "        z = logit_prob + self.eps_h2h * logit_h2h\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "\n",
        "    def _prediction_verbose(self, player1, player2):\n",
        "        if self.verbose:\n",
        "            for player in (player1, player2):\n",
        "                if player not in self.params:\n",
        "                    print(f'Player \"{player}\" not found. Initialize param: {self.base_param}')\n",
        "\n",
        "\n",
        "\n",
        "    def _add_player(self, player, param=None):\n",
        "        \"\"\"\n",
        "        Add a new player with an optional custom param.\n",
        "\n",
        "        :param player: Name of the player.\n",
        "        :param rating: Custom initial rating (defaults to base_rating if not provided).\n",
        "        \"\"\"\n",
        "        if player not in self.params:\n",
        "            self.params[player] = param if param is not None else self.base_param\n",
        "\n",
        "\n",
        "\n",
        "    def display_params(self, round_digits=2, first_n=None):\n",
        "        \"\"\"\n",
        "        Display the current ratings of all players, rounded to the specified number of digits.\n",
        "\n",
        "        :param round_digits: Number of decimal places to round the parameters. Default is 2.\n",
        "        :param first_n: If specified, only display the top `first_n` players based on their ratings.\n",
        "        \"\"\"\n",
        "        # Sort players by the first element of their parameter tuple in descending order\n",
        "        sorted_params = sorted(self.params.items(), key=lambda x: x[1][0], reverse=True)\n",
        "\n",
        "        # Limit the list to the first `first_n` players if specified\n",
        "        if first_n is not None:\n",
        "            sorted_params = sorted_params[:first_n]\n",
        "\n",
        "        # Display the parameters\n",
        "        for player, param in sorted_params:\n",
        "            rounded_param = tuple(round(value, round_digits) for value in param)\n",
        "            print(f\"{player}: {rounded_param}\")\n",
        "\n",
        "\n",
        "\n",
        "    def _update_eps(self, expected1, result1, h2h):\n",
        "        return (expected1 - result1) * self._logit(h2h)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _update_params(self, player1, player2, result1, h2h):\n",
        "        \"\"\"\n",
        "        Update ratings for two players after a match.\n",
        "\n",
        "        :param player1: Name or identifier of Player 1.\n",
        "        :param player2: Name or identifier of Player 2.\n",
        "        :param result1: Result for Player 1 (points1 / points_tot).\n",
        "        \"\"\"\n",
        "        found_p1, param1 = self.get_player_param(player1)\n",
        "        found_p2, param2 = self.get_player_param(player2)\n",
        "\n",
        "        expected1 = self._expected_prob(param1, param2)\n",
        "        expected1 = self._correction_prob(expected1, h2h)\n",
        "        mu_diff = param1[0] - param2[0]\n",
        "        sigma_tot = self._add_sigma(param1[1], param2[1])\n",
        "\n",
        "        # Calculate updates\n",
        "        mu1_update = (expected1 - result1) / sigma_tot\n",
        "        mu2_update = - (expected1 - result1) / sigma_tot\n",
        "        sigma1_update = sigma2_update = 0\n",
        "        if self.update_sigma:\n",
        "            sigma1_update = (-mu_diff * param1[1]) / sigma_tot**3 * (expected1 - result1)\n",
        "            sigma2_update = (-mu_diff * param2[1]) / sigma_tot**3 * (expected1 - result1)\n",
        "\n",
        "        # Update ratings and assign new tuples\n",
        "        self.params[player1] = (\n",
        "            param1[0] - self.learning_rate * mu1_update,\n",
        "            param1[1] - self.learning_rate * sigma1_update\n",
        "        )\n",
        "        self.params[player2] = (\n",
        "            param2[0] - self.learning_rate * mu2_update,\n",
        "            param2[1] - self.learning_rate * sigma2_update\n",
        "        )\n",
        "        self.eps_h2h = self.eps_h2h - self.learning_rate * self._update_eps(expected1, result1, h2h)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pT6ThYQELUOH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ModifiedEloH2H_none(RatingSystem2):\n",
        "    def __init__(self, learning_rate=0.1, base_param=(0, 1), update_sigma=True, binary=False, verbose=False):\n",
        "        \"\"\"\n",
        "        Initialize the rating system.\n",
        "\n",
        "        :param learning_rate: Learning rate.\n",
        "        :param params: Parameters for the players.\n",
        "        :param update_sigma: Update also sigma during the gradient descent.\n",
        "        \"\"\"\n",
        "        super().__init__(learning_rate=learning_rate, binary=binary, verbose=verbose)\n",
        "\n",
        "        if not isinstance(base_param, tuple):\n",
        "            raise TypeError(f\"Expected 'base_param' to be a tuple, but got {type(base_param).__name__}\")\n",
        "        if len(base_param) != 2:\n",
        "            raise ValueError(f\"Expected 'value' to be a 2-entry tuple, but got {len(base_param)} entries\")\n",
        "        if not all(isinstance(entry, (int, float)) for entry in base_param):\n",
        "            raise TypeError(\"Both entries in 'base_param' must be float/int\")\n",
        "        if base_param[1] <= 0:\n",
        "            raise ValueError(f\"The second entry in 'base_param' must be greater than 0, but got {base_param[1]}\")\n",
        "\n",
        "        if not isinstance(update_sigma, bool):\n",
        "            raise TypeError(f\"Expected 'update_sigma' to be an bool, but got {type(update_sigma).__name__}\")\n",
        "\n",
        "        self.params = {}\n",
        "        self.base_param = base_param\n",
        "        self.update_sigma = update_sigma\n",
        "\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"ModifiedElo(learning_rate={self.learning_rate}, base_param={self.base_param}, update_sigma={self.update_sigma}, verbose={self.verbose})\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _get_player_param(self, player):\n",
        "        \"\"\"\n",
        "        Retrieve the current rating of a player. If the player does not exist, use the default.\n",
        "\n",
        "        :param player: The player's name.\n",
        "        :return: Current rating of the player.\n",
        "        \"\"\"\n",
        "        return (player in self.params), self.params.get(player, self.base_param)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _expected_prob(self, param1, param2):\n",
        "        \"\"\"\n",
        "        Calculate the expected prob. of winning a point.\n",
        "\n",
        "        :param param1: Parameters of Player 1.\n",
        "        :param param2: Parameters of Player 2.\n",
        "        :return: Expected prob for Player 1.\n",
        "        \"\"\"\n",
        "        # Calculate the combined sigma and the difference in mu values\n",
        "        z = (param1[0] - param2[0]) / self._add_sigma(param1[1], param2[1])\n",
        "        # Calculate the predicted probability using the logistic function\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "\n",
        "    def _prediction_verbose(self, player1, player2):\n",
        "        if self.verbose:\n",
        "            for player in (player1, player2):\n",
        "                if player not in self.params:\n",
        "                    print(f'Player \"{player}\" not found. Initialize param: {self.base_param}')\n",
        "\n",
        "\n",
        "\n",
        "    def _add_player(self, player, param=None):\n",
        "        \"\"\"\n",
        "        Add a new player with an optional custom param.\n",
        "\n",
        "        :param player: Name of the player.\n",
        "        :param rating: Custom initial rating (defaults to base_rating if not provided).\n",
        "        \"\"\"\n",
        "        if player not in self.params:\n",
        "            self.params[player] = param if param is not None else self.base_param\n",
        "\n",
        "\n",
        "\n",
        "    def display_params(self, round_digits=2, first_n=None):\n",
        "        \"\"\"\n",
        "        Display the current ratings of all players, rounded to the specified number of digits.\n",
        "\n",
        "        :param round_digits: Number of decimal places to round the parameters. Default is 2.\n",
        "        :param first_n: If specified, only display the top `first_n` players based on their ratings.\n",
        "        \"\"\"\n",
        "        # Sort players by the first element of their parameter tuple in descending order\n",
        "        sorted_params = sorted(self.params.items(), key=lambda x: x[1][0], reverse=True)\n",
        "\n",
        "        # Limit the list to the first `first_n` players if specified\n",
        "        if first_n is not None:\n",
        "            sorted_params = sorted_params[:first_n]\n",
        "\n",
        "        # Display the parameters\n",
        "        for player, param in sorted_params:\n",
        "            rounded_param = tuple(round(value, round_digits) for value in param)\n",
        "            print(f\"{player}: {rounded_param}\")\n",
        "\n",
        "\n",
        "\n",
        "    def _update_params(self, player1, player2, result1):\n",
        "        \"\"\"\n",
        "        Update ratings for two players after a match.\n",
        "\n",
        "        :param player1: Name or identifier of Player 1.\n",
        "        :param player2: Name or identifier of Player 2.\n",
        "        :param result1: Result for Player 1 (points1 / points_tot).\n",
        "        \"\"\"\n",
        "        found_p1, param1 = self.get_player_param(player1)\n",
        "        found_p2, param2 = self.get_player_param(player2)\n",
        "\n",
        "        expected1 = self._expected_prob(param1, param2)\n",
        "        mu_diff = param1[0] - param2[0]\n",
        "        sigma_tot = self._add_sigma(param1[1], param2[1])\n",
        "\n",
        "        # Calculate updates\n",
        "        mu1_update = (expected1 - result1) / sigma_tot\n",
        "        mu2_update = - (expected1 - result1) / sigma_tot\n",
        "        sigma1_update = sigma2_update = 0\n",
        "        if self.update_sigma:\n",
        "            sigma1_update = (-mu_diff * param1[1]) / sigma_tot**3 * (expected1 - result1)\n",
        "            sigma2_update = (-mu_diff * param2[1]) / sigma_tot**3 * (expected1 - result1)\n",
        "\n",
        "        # Update ratings and assign new tuples\n",
        "        self.params[player1] = (\n",
        "            param1[0] - self.learning_rate * mu1_update,\n",
        "            param1[1] - self.learning_rate * sigma1_update\n",
        "        )\n",
        "        self.params[player2] = (\n",
        "            param2[0] - self.learning_rate * mu2_update,\n",
        "            param2[1] - self.learning_rate * sigma2_update\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Srl2xluSd3GM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q1JQFeeCWsot"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CBCmreMoWslJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BhwcSvdfWsiC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h2h_mean_train = {}\n",
        "for id in tqdm(df_train.ID.unique()):\n",
        "    h2h_mean_train[id] = np.nan_to_num(h2h_rate_mean[id], nan=0.5)\n",
        "\n",
        "h2h_mean_val = {}\n",
        "for id in tqdm(df_val.ID.unique()):\n",
        "    h2h_mean_val[id] = np.nan_to_num(h2h_rate_mean[id], nan=0.5)\n",
        "\n",
        "h2h_mean_train_val = {}\n",
        "for id in tqdm(df_train_val.ID.unique()):\n",
        "    h2h_mean_train_val[id] = np.nan_to_num(h2h_rate_mean[id], nan=0.5)\n",
        "\n",
        "h2h_mean_test = {}\n",
        "for id in tqdm(df_test.ID.unique()):\n",
        "    h2h_mean_test[id] = np.nan_to_num(h2h_rate_mean[id], nan=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9tadYukJKgQ",
        "outputId": "eef0ad0b-2e72-4499-a391-5804bb1f9718"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26120/26120 [00:00<00:00, 35708.83it/s]\n",
            "100%|██████████| 6490/6490 [00:00<00:00, 39250.09it/s]\n",
            "100%|██████████| 32610/32610 [00:00<00:00, 35685.48it/s]\n",
            "100%|██████████| 1969/1969 [00:00<00:00, 36219.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h2h_median_train = {}\n",
        "for id in tqdm(df_train.ID.unique()):\n",
        "    h2h_median_train[id] = np.nan_to_num(h2h_rate_median[id], nan=0.5)\n",
        "\n",
        "h2h_median_val = {}\n",
        "for id in tqdm(df_val.ID.unique()):\n",
        "    h2h_median_val[id] = np.nan_to_num(h2h_rate_median[id], nan=0.5)\n",
        "\n",
        "h2h_median_train_val = {}\n",
        "for id in tqdm(df_train_val.ID.unique()):\n",
        "    h2h_median_train_val[id] = np.nan_to_num(h2h_rate_median[id], nan=0.5)\n",
        "\n",
        "h2h_median_test = {}\n",
        "for id in tqdm(df_test.ID.unique()):\n",
        "    h2h_median_test[id] = np.nan_to_num(h2h_rate_median[id], nan=0.5)"
      ],
      "metadata": {
        "id": "So3P6YQrsX4k",
        "outputId": "248546a9-d8f7-45fb-e78a-94304f914412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26120/26120 [00:00<00:00, 46697.26it/s]\n",
            "100%|██████████| 6490/6490 [00:00<00:00, 73254.38it/s]\n",
            "100%|██████████| 32610/32610 [00:00<00:00, 61300.09it/s]\n",
            "100%|██████████| 1969/1969 [00:00<00:00, 62150.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h2h_IQR_train = {}\n",
        "for id in tqdm(df_train.ID.unique()):\n",
        "    h2h_IQR_train[id] = np.nan_to_num(h2h_rate_IQR[id], nan=0.5)\n",
        "\n",
        "h2h_IQR_val = {}\n",
        "for id in tqdm(df_val.ID.unique()):\n",
        "    h2h_IQR_val[id] = np.nan_to_num(h2h_rate_IQR[id], nan=0.5)\n",
        "\n",
        "h2h_IQR_train_val = {}\n",
        "for id in tqdm(df_train_val.ID.unique()):\n",
        "    h2h_IQR_train_val[id] = np.nan_to_num(h2h_rate_IQR[id], nan=0.5)\n",
        "\n",
        "h2h_IQR_test = {}\n",
        "for id in tqdm(df_test.ID.unique()):\n",
        "    h2h_IQR_test[id] = np.nan_to_num(h2h_rate_IQR[id], nan=0.5)"
      ],
      "metadata": {
        "id": "QiZz91gfvH5L",
        "outputId": "180bf204-c287-444f-bf5e-bf17baeb0a3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26120/26120 [00:00<00:00, 67563.58it/s]\n",
            "100%|██████████| 6490/6490 [00:00<00:00, 62045.07it/s]\n",
            "100%|██████████| 32610/32610 [00:00<00:00, 69457.67it/s]\n",
            "100%|██████████| 1969/1969 [00:00<00:00, 71670.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_mean = ModifiedEloH2H()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMEloH2H_mean.fit(X_train, h2h_mean_train)\n"
      ],
      "metadata": {
        "id": "J6k5cQeBLURI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5cac70-b49a-4deb-fb0f-1aea4ce517af"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15326.14it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15569.40it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15689.96it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15405.61it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 13736.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_median = ModifiedEloH2H()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMEloH2H_median.fit(X_train, h2h_median_train)\n"
      ],
      "metadata": {
        "id": "r2BuSMnGsbRh",
        "outputId": "7b8d7b2f-56b3-40f3-a153-0b793c69d6e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 26120/26120 [00:02<00:00, 10230.25it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15582.74it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15587.41it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15788.93it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15536.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_IQR = ModifiedEloH2H()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMEloH2H_IQR.fit(X_train, h2h_IQR_train)\n"
      ],
      "metadata": {
        "id": "Ba5tSejqvVmc",
        "outputId": "b84d60ad-ddf8-4433-e686-b282cb3736b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15313.96it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:02<00:00, 12055.56it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:02<00:00, 9708.99it/s] \n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15697.86it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 15415.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_none = ModifiedEloH2H_none()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMEloH2H_none.fit(X_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8b09FDsduV0",
        "outputId": "3cd5ddae-2cb2-4214-e3b8-c5bdfbd1f863"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 21903.68it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 22480.92it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 22480.09it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 22284.17it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 17039.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMElo = ModifiedElo()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMElo.fit(X_train)\n"
      ],
      "metadata": {
        "id": "pE6gAsF8jBjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a761337-b615-46a5-93bc-8ad5fd09ae99"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 13751.81it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 22713.55it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 22945.71it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 22702.55it/s]\n",
            "Training model: 100%|██████████| 26120/26120 [00:01<00:00, 23066.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_mean.eps_h2h"
      ],
      "metadata": {
        "id": "4r29uF0mjBb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cd6286-f344-464a-98a7-e47b34587607"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2833201839068169"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_median.eps_h2h"
      ],
      "metadata": {
        "id": "rQS7ILsssg8U",
        "outputId": "6dea417c-03fb-4ece-bef4-e92f04eab0d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16398489825012655"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_IQR.eps_h2h"
      ],
      "metadata": {
        "id": "aoF52a-rvZ-q",
        "outputId": "6da0b7f3-7fcb-4b7e-c232-b277ef8ac3ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26800301401839965"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataset):\n",
        "    print(f\"Evaluate model: {repr(model)}\")\n",
        "    _model = copy.deepcopy(model)\n",
        "    _model.verbose = False\n",
        "    correct = 0\n",
        "    n_matches = 0\n",
        "\n",
        "    history = []\n",
        "    predictions = []\n",
        "    for matchi in tqdm(dataset, desc=\"Evaluating matches\"):\n",
        "        matchi = matchi.T\n",
        "        player1, player2 = matchi[1]\n",
        "\n",
        "        found_p1, found_p2, p = _model.predict_point(player1, player2)\n",
        "        if not (found_p1 and found_p2): continue\n",
        "        if p == 0.5: continue\n",
        "        whowillwin = 0 if p > 0.5 else 1\n",
        "\n",
        "        win1 = sum(matchi[2:, 0]>matchi[2:, 1])\n",
        "        win2 = sum(matchi[2:, 0]<matchi[2:, 1])\n",
        "        whowon = 0 if win1 > win2 else 1\n",
        "\n",
        "        history.append(win1/(win1 + win2))\n",
        "        predictions.append(p)\n",
        "\n",
        "        n_matches += 1\n",
        "        if (whowon == whowillwin): correct += 1\n",
        "\n",
        "    acc = correct / n_matches\n",
        "    print(f'\\n === Accuracy: {acc} === \\n\\n')\n",
        "    return acc, np.array(history), np.array(predictions)\n"
      ],
      "metadata": {
        "id": "__lwyVLBJEPY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateH2H(model, dataset, h2h):\n",
        "    print(f\"Evaluate model: {repr(model)}\")\n",
        "    _model = copy.deepcopy(model)\n",
        "    _model.verbose = False\n",
        "    correct = 0\n",
        "    n_matches = 0\n",
        "\n",
        "    history = []\n",
        "    predictions = []\n",
        "    for matchi in tqdm(dataset, desc=\"Evaluating matches\"):\n",
        "        matchi = matchi.T\n",
        "        h2hi = h2h[matchi[0, 0]]\n",
        "        player1, player2 = matchi[1]\n",
        "\n",
        "        found_p1, found_p2, p = _model.predict_point(player1, player2, h2hi)\n",
        "        if not (found_p1 and found_p2): continue\n",
        "        if p == 0.5: continue\n",
        "        whowillwin = 0 if p > 0.5 else 1\n",
        "\n",
        "        win1 = sum(matchi[2:, 0]>matchi[2:, 1])\n",
        "        win2 = sum(matchi[2:, 0]<matchi[2:, 1])\n",
        "        whowon = 0 if win1 > win2 else 1\n",
        "\n",
        "\n",
        "        history.append(win1/(win1 + win2))\n",
        "        predictions.append(p)\n",
        "\n",
        "        n_matches += 1\n",
        "        if (whowon == whowillwin): correct += 1\n",
        "\n",
        "    acc = correct / n_matches\n",
        "    print(f'\\n === Accuracy: {acc} === \\n\\n')\n",
        "    return acc, np.array(history), np.array(predictions)\n"
      ],
      "metadata": {
        "id": "Fm0aGo6gjBYZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_h2h, hist_h2h, pred_h2h = evaluateH2H(modelMEloH2H_mean, X_train, h2h_mean_train);\n",
        "acc_h2h, hist_h2h, pred_h2h = evaluateH2H(modelMEloH2H_median, X_train, h2h_median_train);\n",
        "acc_h2h, hist_h2h, pred_h2h = evaluateH2H(modelMEloH2H_IQR, X_train, h2h_IQR_train);\n",
        "acc, hist, pred = evaluate(modelMEloH2H_none, X_train);\n",
        "acc, hist, pred = evaluate(modelMElo, X_train);\n",
        "(acc_h2h - acc) * 100"
      ],
      "metadata": {
        "id": "1Cm_LWGEjBVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf33f73-2fcd-4a05-c061-09432f8a5132"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 26120/26120 [00:00<00:00, 39967.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6666539050535988 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 26120/26120 [00:00<00:00, 37416.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6588820826952527 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 26120/26120 [00:00<00:00, 39590.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6658882082695252 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 26120/26120 [00:00<00:00, 49355.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6505359877488515 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 26120/26120 [00:00<00:00, 46452.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6505359877488515 === \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5352220520673754"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_h2h, hist_h2h, pred_h2h = evaluateH2H(modelMEloH2H_mean, X_val, h2h_mean_val);\n",
        "acc_h2h, hist_h2h, pred_h2h = evaluateH2H(modelMEloH2H_median, X_val, h2h_median_val);\n",
        "acc_h2h, hist_h2h, pred_h2h = evaluateH2H(modelMEloH2H_IQR, X_val, h2h_IQR_val);\n",
        "acc, hist, pred = evaluate(modelMEloH2H_none, X_val);\n",
        "acc, hist, pred = evaluate(modelMElo, X_val);\n",
        "(acc_h2h - acc) * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J856eQO3JmLn",
        "outputId": "2ff25640-6b7b-4737-8b2d-20b7826fcabd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 6490/6490 [00:00<00:00, 45201.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6031143182681352 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 6490/6490 [00:00<00:00, 47893.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.59684770224079 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 6490/6490 [00:00<00:00, 40378.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.600835548803646 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 6490/6490 [00:00<00:00, 44926.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.5928598556779339 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 6490/6490 [00:00<00:00, 58519.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.5928598556779339 === \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7975693125712113"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_mean = ModifiedEloH2H()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMEloH2H_mean.fit(X_train_val, h2h_mean_train_val)\n"
      ],
      "metadata": {
        "id": "I8ETye_ULeXR",
        "outputId": "4ae1ef11-3d90-462c-8364-16f7f860b800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 11720.26it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 12617.87it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15596.17it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15360.17it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15638.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_median = ModifiedEloH2H()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMEloH2H_median.fit(X_train_val, h2h_median_train_val)\n"
      ],
      "metadata": {
        "id": "_-9-7Cp0tTD_",
        "outputId": "c2b9b65b-307a-4396-a24b-c29c5f8e1e19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15282.13it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:03<00:00, 9890.61it/s] \n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15474.76it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15227.84it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15449.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_IQR = ModifiedEloH2H()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMEloH2H_IQR.fit(X_train_val, h2h_IQR_train_val)\n"
      ],
      "metadata": {
        "id": "oV-PSGKOwOoZ",
        "outputId": "d8e98857-08e5-43cb-b36c-1b6dc8498995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15356.54it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:03<00:00, 10671.03it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 13825.40it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15425.23it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 15262.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMEloH2H_none = ModifiedEloH2H_none()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMEloH2H_none.fit(X_train_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qVJ6HE4jnyc",
        "outputId": "7cf5df1f-1a1d-47e8-8be3-b13469de10fb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 32610/32610 [00:01<00:00, 22274.39it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:01<00:00, 22234.84it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:01<00:00, 17328.16it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:02<00:00, 14993.61it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:01<00:00, 22313.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelMElo = ModifiedElo()\n",
        "\n",
        "# traing model with only training set\n",
        "for _ in range(5):\n",
        "    modelMElo.fit(X_train_val)\n"
      ],
      "metadata": {
        "id": "PyfWmG9dMFt1",
        "outputId": "7684f4fb-e7bb-42f7-e994-f2e7e2b4eb28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model: 100%|██████████| 32610/32610 [00:01<00:00, 21825.49it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:01<00:00, 22175.27it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:01<00:00, 22325.25it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:01<00:00, 21716.65it/s]\n",
            "Training model: 100%|██████████| 32610/32610 [00:01<00:00, 22078.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_h2h, hist_h2h, pred_h2h = evaluateH2H(modelMEloH2H_mean, X_test, h2h_mean_test);\n",
        "acc_h2h, hist_h2h, pred_h2h = evaluateH2H(modelMEloH2H_median, X_test, h2h_median_test);\n",
        "acc_h2h, hist_h2h, pred_h2h = evaluateH2H(modelMEloH2H_IQR, X_test, h2h_IQR_test);\n",
        "acc, hist, pred = evaluate(modelMEloH2H_none, X_test);\n",
        "acc, hist, pred = evaluate(modelMElo, X_test);\n",
        "(acc_h2h - acc) * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEwtwWOOJlru",
        "outputId": "7a89fbe2-d985-4201-b7c2-f33ea1e6abd4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 1969/1969 [00:00<00:00, 41658.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6629834254143646 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 1969/1969 [00:00<00:00, 43256.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6729281767955801 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 1969/1969 [00:00<00:00, 42908.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6629834254143646 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 1969/1969 [00:00<00:00, 52896.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6585635359116022 === \n",
            "\n",
            "\n",
            "Evaluate model: ModifiedElo(learning_rate=0.1, base_param=(0, 1), update_sigma=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating matches: 100%|██████████| 1969/1969 [00:00<00:00, 48093.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " === Accuracy: 0.6585635359116022 === \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44198895027623974"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w8N0UOpEJ7up"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9v5WgiRJ9CM"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}